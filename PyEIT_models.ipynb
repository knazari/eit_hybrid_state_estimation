{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "37jXQv5tgQXJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5YnaNweblI",
        "outputId": "99f5a892-568a-426e-9e64-ecd9b0c5d0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”§ Training Transformer Regressor...\n",
            "Epoch   0 | Loss: 0.809660\n",
            "Epoch  50 | Loss: 0.025465\n",
            "Epoch 100 | Loss: 0.039520\n",
            "Epoch 150 | Loss: 0.032006\n",
            "Epoch 200 | Loss: 0.027571\n",
            "Epoch 250 | Loss: 0.020881\n",
            "Epoch 300 | Loss: 0.061110\n",
            "Epoch 350 | Loss: 0.010580\n",
            "Epoch 400 | Loss: 0.019286\n",
            "Epoch 450 | Loss: 0.026459\n",
            "Epoch 500 | Loss: 0.009672\n",
            "Epoch 550 | Loss: 0.013310\n",
            "Epoch 600 | Loss: 0.004204\n",
            "Epoch 650 | Loss: 0.060574\n",
            "Epoch 700 | Loss: 0.012968\n",
            "Epoch 750 | Loss: 0.007417\n",
            "Epoch 800 | Loss: 0.030547\n",
            "Epoch 850 | Loss: 0.006928\n",
            "Epoch 900 | Loss: 0.009704\n",
            "Epoch 950 | Loss: 0.008481\n",
            "Epoch 999 | Loss: 0.004332\n",
            "\n",
            "ðŸ“Š Transformer Model Performance:\n",
            "MAE - X:     0.0203\n",
            "MAE - Y:     0.0191\n",
            "MAE - Force: 0.0516\n",
            "RÂ²  - X:     0.9937\n",
            "RÂ²  - Y:     0.9951\n",
            "RÂ²  - Force: 0.9152\n",
            "âœ… Training complete. Plots saved in 'data/'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# === Load data ===\n",
        "df = pd.read_csv(\"touch_force_dataset.csv\")\n",
        "X = df.iloc[:, :-3].values\n",
        "y = df.iloc[:, -3:].values\n",
        "\n",
        "# === Split and scale ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "y_test_scaled = scaler_y.transform(y_test)\n",
        "\n",
        "# === Convert to tensors ===\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(-1)  # (N, 208, 1)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(-1)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
        "\n",
        "X_train_scaled = X_train_tensor.to(device)\n",
        "X_test_tensor = X_test_tensor.to(device)\n",
        "y_train_tensor = y_train_tensor.to(device)\n",
        "y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "# === Transformer Model ===\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
        "\n",
        "class TransformerRegressor(nn.Module):\n",
        "    def __init__(self, seq_len=208, d_model=64, nhead=8, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(1, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=seq_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=128, dropout=0.1, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(d_model, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # x: (B, 208, 1)\n",
        "        x = self.input_proj(x)           # (B, 208, d_model)\n",
        "        x = self.pos_encoder(x)          # (B, 208, d_model)\n",
        "        x = self.transformer(x)          # (B, 208, d_model)\n",
        "        x = x.mean(dim=1)                # Global average pooling\n",
        "        return self.regressor(x)         # (B, 3)\n",
        "\n",
        "model = TransformerRegressor().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# === Training loop ===\n",
        "epochs = 1000\n",
        "batch_size = 64\n",
        "print(\"ðŸ”§ Training Transformer Regressor...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    perm = torch.randperm(X_train_tensor.size(0))\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        idx = perm[i:i+batch_size]\n",
        "        x_batch = X_train_tensor[idx].to(device)\n",
        "        y_batch = y_train_tensor[idx].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x_batch).to(device)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0 or epoch == epochs - 1:\n",
        "        print(f\"Epoch {epoch:3d} | Loss: {loss.item():.6f}\")\n",
        "\n",
        "# === Evaluation ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_test_unscaled = scaler_y.inverse_transform(y_test_tensor.cpu().numpy())\n",
        "\n",
        "# === Metrics ===\n",
        "mae = mean_absolute_error(y_test_unscaled, y_pred, multioutput=\"raw_values\")\n",
        "r2 = r2_score(y_test_unscaled, y_pred, multioutput=\"raw_values\")\n",
        "\n",
        "print(\"\\nðŸ“Š Transformer Model Performance:\")\n",
        "print(f\"MAE - X:     {mae[0]:.4f}\")\n",
        "print(f\"MAE - Y:     {mae[1]:.4f}\")\n",
        "print(f\"MAE - Force: {mae[2]:.4f}\")\n",
        "print(f\"RÂ²  - X:     {r2[0]:.4f}\")\n",
        "print(f\"RÂ²  - Y:     {r2[1]:.4f}\")\n",
        "print(f\"RÂ²  - Force: {r2[2]:.4f}\")\n",
        "\n",
        "# === Plot predictions ===\n",
        "labels = [\"x\", \"y\", \"force\"]\n",
        "for i in range(3):\n",
        "    plt.figure(figsize=(4.5, 4))\n",
        "    plt.scatter(y_test_unscaled[:, i], y_pred[:, i], alpha=0.7)\n",
        "    plt.xlabel(f\"True {labels[i]}\")\n",
        "    plt.ylabel(f\"Predicted {labels[i]}\")\n",
        "    plt.title(f\"Transformer Prediction: {labels[i]}\")\n",
        "    plt.grid(True)\n",
        "    plt.axis(\"equal\")\n",
        "    plt.plot([min(y_test_unscaled[:, i]), max(y_test_unscaled[:, i])],\n",
        "             [min(y_test_unscaled[:, i]), max(y_test_unscaled[:, i])],\n",
        "             'r--')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"transformer_pred_{labels[i]}.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "print(\"âœ… Training complete. Plots saved in 'data/'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# === Set output folder ===\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# === GPU/CPU setup ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"âœ… Using device:\", device)\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"touch_force_dataset.csv\")\n",
        "X = df.iloc[:, :-3].values\n",
        "y = df.iloc[:, -3:].values\n",
        "\n",
        "# === Train/test split and normalization ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "y_test_scaled = scaler_y.transform(y_test)\n",
        "\n",
        "# === Tensor conversion ===\n",
        "X_train_tensor = torch.tensor(X_train_scaled[:, np.newaxis, :], dtype=torch.float32).to(device)  # (N, 1, 208)\n",
        "X_test_tensor = torch.tensor(X_test_scaled[:, np.newaxis, :], dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "# === Positional Encoding ===\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
        "\n",
        "# === CNN + Transformer hybrid ===\n",
        "class CNNTransformerRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),  # output: (32, 104)\n",
        "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)   # output: (64, 52)\n",
        "        )\n",
        "        self.proj = nn.Linear(64, 64)\n",
        "        self.pos_encoder = PositionalEncoding(d_model=64, max_len=52)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8, dim_feedforward=128, dropout=0.1, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # x: (B, 1, 208)\n",
        "        x = self.cnn(x)              # (B, 64, 52)\n",
        "        x = x.permute(0, 2, 1)       # (B, 52, 64)\n",
        "        x = self.proj(x)             # ensure model dim matches\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer(x)      # (B, 52, 64)\n",
        "        x = x.mean(dim=1)            # Global average pooling\n",
        "        return self.regressor(x)\n",
        "\n",
        "# === Initialize ===\n",
        "model = CNNTransformerRegressor().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# === Training loop ===\n",
        "epochs = 500\n",
        "batch_size = 64\n",
        "print(\"ðŸ”§ Training CNN + Transformer Model...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    perm = torch.randperm(X_train_tensor.size(0))\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        idx = perm[i:i+batch_size]\n",
        "        x_batch = X_train_tensor[idx]\n",
        "        y_batch = y_train_tensor[idx]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0 or epoch == epochs - 1:\n",
        "        print(f\"Epoch {epoch:3d} | Loss: {loss.item():.6f}\")\n",
        "\n",
        "# === Evaluation ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_test_unscaled = scaler_y.inverse_transform(y_test_tensor.cpu().numpy())\n",
        "\n",
        "# === Metrics ===\n",
        "mae = mean_absolute_error(y_test_unscaled, y_pred, multioutput=\"raw_values\")\n",
        "r2 = r2_score(y_test_unscaled, y_pred, multioutput=\"raw_values\")\n",
        "\n",
        "print(\"\\nðŸ“Š CNN + Transformer Performance:\")\n",
        "print(f\"MAE - X:     {mae[0]:.4f}\")\n",
        "print(f\"MAE - Y:     {mae[1]:.4f}\")\n",
        "print(f\"MAE - Force: {mae[2]:.4f}\")\n",
        "print(f\"RÂ²  - X:     {r2[0]:.4f}\")\n",
        "print(f\"RÂ²  - Y:     {r2[1]:.4f}\")\n",
        "print(f\"RÂ²  - Force: {r2[2]:.4f}\")\n",
        "\n",
        "# === Plot ===\n",
        "labels = [\"x\", \"y\", \"force\"]\n",
        "for i in range(3):\n",
        "    plt.figure(figsize=(4.5, 4))\n",
        "    plt.scatter(y_test_unscaled[:, i], y_pred[:, i], alpha=0.7)\n",
        "    plt.xlabel(f\"True {labels[i]}\")\n",
        "    plt.ylabel(f\"Predicted {labels[i]}\")\n",
        "    plt.title(f\"Hybrid Model Prediction: {labels[i]}\")\n",
        "    plt.grid(True)\n",
        "    plt.axis(\"equal\")\n",
        "    plt.plot([min(y_test_unscaled[:, i]), max(y_test_unscaled[:, i])],\n",
        "             [min(y_test_unscaled[:, i]), max(y_test_unscaled[:, i])],\n",
        "             'r--')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"outputs/cnn_transformer_{labels[i]}.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "print(\"\\nâœ… Training complete. Prediction plots saved to '/content/outputs/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJFQzS3Mo4iE",
        "outputId": "121ecb77-a2a4-4d44-9dfe-12bd14fd0678"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using device: cuda\n",
            "ðŸ”§ Training CNN + Transformer Model...\n",
            "Epoch   0 | Loss: 0.918251\n",
            "Epoch  50 | Loss: 0.041723\n",
            "Epoch 100 | Loss: 0.024288\n",
            "Epoch 150 | Loss: 0.031773\n",
            "Epoch 200 | Loss: 0.007061\n",
            "Epoch 250 | Loss: 0.017170\n",
            "Epoch 300 | Loss: 0.010626\n",
            "Epoch 350 | Loss: 0.014407\n",
            "Epoch 400 | Loss: 0.004340\n",
            "Epoch 450 | Loss: 0.008311\n",
            "Epoch 499 | Loss: 0.005354\n",
            "\n",
            "ðŸ“Š CNN + Transformer Performance:\n",
            "MAE - X:     0.0159\n",
            "MAE - Y:     0.0143\n",
            "MAE - Force: 0.0526\n",
            "RÂ²  - X:     0.9968\n",
            "RÂ²  - Y:     0.9974\n",
            "RÂ²  - Force: 0.9095\n",
            "\n",
            "âœ… Training complete. Prediction plots saved to '/content/outputs/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Physics-informed CNN"
      ],
      "metadata": {
        "id": "g4remeoBtKyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# === Output path ===\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# === Device setup ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"âœ… Using device:\", device)\n",
        "\n",
        "# === Load data ===\n",
        "df = pd.read_csv(\"touch_force_dataset.csv\")\n",
        "X = df.iloc[:, :-3].values\n",
        "y = df.iloc[:, -3:].values\n",
        "\n",
        "# === Train/test split and normalization ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "y_test_scaled = scaler_y.transform(y_test)\n",
        "\n",
        "# === Tensor conversion ===\n",
        "X_train_tensor = torch.tensor(X_train_scaled[:, np.newaxis, :], dtype=torch.float32).to(device)  # (N, 1, 208)\n",
        "X_test_tensor = torch.tensor(X_test_scaled[:, np.newaxis, :], dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "# === CNN Model ===\n",
        "class CNNRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),  # (B, 32, 104)\n",
        "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),  # (B, 64, 52)\n",
        "            nn.Flatten(),     # (B, 64*52)\n",
        "            nn.Linear(64 * 52, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# === Initialize ===\n",
        "model = CNNRegressor().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "lambda_phys = 0.01  # weight of physics-informed loss\n",
        "\n",
        "# === Training ===\n",
        "epochs = 700\n",
        "batch_size = 64\n",
        "print(\"ðŸ”§ Training Physics-Informed CNN...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    perm = torch.randperm(X_train_tensor.size(0))\n",
        "\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        idx = perm[i:i + batch_size]\n",
        "        x_batch = X_train_tensor[idx]\n",
        "        y_batch = y_train_tensor[idx]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x_batch)\n",
        "        loss_pred = loss_fn(y_pred, y_batch)\n",
        "\n",
        "        # === Physics-informed loss (monotonicity) ===\n",
        "        v_diff_norm = torch.norm(x_batch.squeeze(1), dim=1)  # raw Î”V magnitude\n",
        "        force_pred = y_pred[:, 2]\n",
        "        # Normalize both\n",
        "        v_diff_norm = (v_diff_norm - v_diff_norm.mean()) / v_diff_norm.std()\n",
        "        force_pred_norm = (force_pred - force_pred.mean()) / force_pred.std()\n",
        "\n",
        "        loss_phys = loss_fn(v_diff_norm, force_pred_norm)\n",
        "\n",
        "        total_loss = loss_pred + lambda_phys * loss_phys\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0 or epoch == epochs - 1:\n",
        "        print(f\"Epoch {epoch:3d} | Pred Loss: {loss_pred.item():.6f} | Phys Loss: {loss_phys.item():.6f}\")\n",
        "\n",
        "# === Evaluation ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_test_unscaled = scaler_y.inverse_transform(y_test_tensor.cpu().numpy())\n",
        "\n",
        "# === Metrics ===\n",
        "mae = mean_absolute_error(y_test_unscaled, y_pred, multioutput=\"raw_values\")\n",
        "r2 = r2_score(y_test_unscaled, y_pred, multioutput=\"raw_values\")\n",
        "\n",
        "print(\"\\nðŸ“Š Physics-Informed CNN Performance:\")\n",
        "print(f\"MAE - X:     {mae[0]:.4f}\")\n",
        "print(f\"MAE - Y:     {mae[1]:.4f}\")\n",
        "print(f\"MAE - Force: {mae[2]:.4f}\")\n",
        "print(f\"RÂ²  - X:     {r2[0]:.4f}\")\n",
        "print(f\"RÂ²  - Y:     {r2[1]:.4f}\")\n",
        "print(f\"RÂ²  - Force: {r2[2]:.4f}\")\n",
        "\n",
        "# === Plot predictions ===\n",
        "labels = [\"x\", \"y\", \"force\"]\n",
        "for i in range(3):\n",
        "    plt.figure(figsize=(4.5, 4))\n",
        "    plt.scatter(y_test_unscaled[:, i], y_pred[:, i], alpha=0.7)\n",
        "    plt.xlabel(f\"True {labels[i]}\")\n",
        "    plt.ylabel(f\"Predicted {labels[i]}\")\n",
        "    plt.title(f\"Physics-Informed CNN Prediction: {labels[i]}\")\n",
        "    plt.grid(True)\n",
        "    plt.axis(\"equal\")\n",
        "    plt.plot(\n",
        "        [min(y_test_unscaled[:, i]), max(y_test_unscaled[:, i])],\n",
        "        [min(y_test_unscaled[:, i]), max(y_test_unscaled[:, i])],\n",
        "        \"r--\",\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"outputs/phys_cnn_pred_{labels[i]}.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "print(\"âœ… Training complete. Plots saved in 'outputs/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3IrQNmitI2Y",
        "outputId": "7132513f-5eb8-4368-e964-85dfc6936f5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using device: cuda\n",
            "ðŸ”§ Training Physics-Informed CNN...\n",
            "Epoch   0 | Pred Loss: 0.206990 | Phys Loss: 0.699358\n",
            "Epoch  50 | Pred Loss: 0.032033 | Phys Loss: 0.884131\n",
            "Epoch 100 | Pred Loss: 0.016652 | Phys Loss: 1.200459\n",
            "Epoch 150 | Pred Loss: 0.004111 | Phys Loss: 1.470896\n",
            "Epoch 200 | Pred Loss: 0.011548 | Phys Loss: 0.587657\n",
            "Epoch 250 | Pred Loss: 0.008346 | Phys Loss: 0.954195\n",
            "Epoch 300 | Pred Loss: 0.002399 | Phys Loss: 0.706706\n",
            "Epoch 350 | Pred Loss: 0.002182 | Phys Loss: 0.446137\n",
            "Epoch 400 | Pred Loss: 0.005578 | Phys Loss: 0.641890\n",
            "Epoch 450 | Pred Loss: 0.004999 | Phys Loss: 0.587430\n",
            "Epoch 500 | Pred Loss: 0.001362 | Phys Loss: 1.512943\n",
            "Epoch 550 | Pred Loss: 0.002285 | Phys Loss: 1.105213\n",
            "Epoch 600 | Pred Loss: 0.010008 | Phys Loss: 0.722931\n",
            "Epoch 650 | Pred Loss: 0.008182 | Phys Loss: 0.548184\n",
            "Epoch 699 | Pred Loss: 0.002204 | Phys Loss: 0.942559\n",
            "\n",
            "ðŸ“Š Physics-Informed CNN Performance:\n",
            "MAE - X:     0.0086\n",
            "MAE - Y:     0.0096\n",
            "MAE - Force: 0.0442\n",
            "RÂ²  - X:     0.9988\n",
            "RÂ²  - Y:     0.9981\n",
            "RÂ²  - Force: 0.9402\n",
            "âœ… Training complete. Plots saved in 'outputs/'\n"
          ]
        }
      ]
    }
  ]
}